{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Finding Lane Lines\n",
    "\n",
    "### Describing the pipeline\n",
    "\n",
    "My pipeline consisted of 7 steps. First, I converted the images to grayscale, then I applied gaussian blur using kernel size 7 to reduce undesirable lines, then I applied canny edge detector and after a ROI was applied but I modified the vertices. Now I can finally use hough transform to find lines in the image.\n",
    "\n",
    "In order to draw a single line on the left and right lanes, I modified the draw_lines() function for separate points calculating slopes and intercepts, I used slopes positives for right and negatives for left. So I calculate average for slopes and intercepts to fit stable lines. Finally I draw the lines in the initial image.\n",
    "\n",
    "\n",
    "### Shortcomings\n",
    "\n",
    "One potential shortcoming would be what would happen when sunlight reflect in the road \"creating a new light line\".\n",
    "\n",
    "### Improvements\n",
    "\n",
    "One potential improvement would be in the segmentation algorithm, maybe using color range would be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import HTML\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    #return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img, lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=8):\n",
    "    # separate left line and right line\n",
    "    left_line_x = []\n",
    "    left_line_y = []\n",
    "    left_slopes = []\n",
    "    left_intercepts = []\n",
    "    right_line_x = []\n",
    "    right_line_y = []\n",
    "    right_slopes = []\n",
    "    right_intercepts = []    \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            if math.fabs(slope) < 0.5:\n",
    "                continue            \n",
    "            if slope < 0.0 and slope > -math.inf:\n",
    "                left_line_x.extend([x1, x2])\n",
    "                left_line_y.extend([y1, y2])\n",
    "                left_slopes.append(slope)\n",
    "                left_intercepts.append(y1 - slope*x1)\n",
    "            if slope > 0.0 and slope < math.inf:\n",
    "                right_line_x.extend([x1, x2])\n",
    "                right_line_y.extend([y1, y2])\n",
    "                right_slopes.append(slope)\n",
    "                right_intercepts.append(y1 - slope*x1)\n",
    "                \n",
    "    y_max = img.shape[0]\n",
    "    y_min = int(y_max * 0.6)\n",
    "    \n",
    "    if len(left_slopes) > 0:\n",
    "        left_slope = np.mean(left_slopes)\n",
    "        left_intercept = np.mean(left_intercepts)\n",
    "        x_min_left = int((y_min - left_intercept)/left_slope) \n",
    "        x_max_left = int((y_max - left_intercept)/left_slope)\n",
    "        cv2.line(img, (x_min_left, y_min), (x_max_left, y_max), color, thickness)\n",
    "    \n",
    "    if len(right_slopes) > 0:\n",
    "        right_slope = np.mean(right_slopes)\n",
    "        right_intercept = np.mean(right_intercepts)\n",
    "        x_min_right = int((y_min - right_intercept)/right_slope) \n",
    "        x_max_right = int((y_max - right_intercept)/right_slope)\n",
    "        cv2.line(img, (x_min_right, y_min), (x_max_right, y_max), color, thickness)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, α=0.8, β=1., γ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + γ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image):\n",
    "    image_gray = grayscale(image)\n",
    "    image_blur = gaussian_blur(image_gray, 7)\n",
    "    image_canny = canny(image_blur, 50, 150)\n",
    "    \n",
    "    #imshape = image_canny.shape\n",
    "    #vertices = np.array([[(20,imshape[0]),(450, 330), (520, 330), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    \n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    vertices = np.array([[(100,height),(width*.48, height*0.6), (width*.55, height*0.6), (width,height)]], dtype=np.int32)\n",
    "    \n",
    "    image_roi = region_of_interest(image_canny, vertices)\n",
    "    #image_lines, lines = hough_lines(image_roi, 2, np.pi/180, 18, 40, 20)\n",
    "    image_lines, lines = hough_lines(image_roi, 1, np.pi/180, 15, 30, 10)\n",
    "    image_final = weighted_img(image_lines, image)\n",
    "    \n",
    "    return image_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform on images\n",
    "path_imgs = \"test_images/\"\n",
    "path_imgs_output = \"test_images_output/\"\n",
    "img_files = os.listdir(path_imgs)\n",
    "for file in img_files:\n",
    "   image = mpimg.imread(path_imgs + file)\n",
    "   image_final = process(image)\n",
    "   mpimg.imsave(path_imgs_output + file, image_final)\n",
    "    \n",
    "# perform on videos    \n",
    "path_videos = \"test_videos/\"\n",
    "path_videos_output = \"test_videos_output/\"\n",
    "video_files = os.listdir(path_videos)\n",
    "for file in video_files:\n",
    "    video = VideoFileClip(path_videos + file)\n",
    "    video_processed = video.fl_image(process)\n",
    "    %time video_processed.write_videofile(path_videos_output + file, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
